{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Convolution2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianhao/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 19s 387us/sample - loss: 1.3252 - accuracy: 0.5516\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 19s 379us/sample - loss: 0.8179 - accuracy: 0.7154\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.5952 - accuracy: 0.7921\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 19s 376us/sample - loss: 0.4269 - accuracy: 0.8520\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 19s 388us/sample - loss: 0.2874 - accuracy: 0.9001\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 20s 394us/sample - loss: 0.2039 - accuracy: 0.9298\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1493 - accuracy: 0.9492\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 19s 383us/sample - loss: 0.1189 - accuracy: 0.9593\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 20s 392us/sample - loss: 0.1130 - accuracy: 0.9605\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 20s 394us/sample - loss: 0.1063 - accuracy: 0.9626\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 19s 385us/sample - loss: 0.0877 - accuracy: 0.9700\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 20s 391us/sample - loss: 0.0857 - accuracy: 0.9703\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 21s 411us/sample - loss: 0.0790 - accuracy: 0.9731\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 21s 415us/sample - loss: 0.0765 - accuracy: 0.9744\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 21s 420us/sample - loss: 0.0591 - accuracy: 0.9797\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 21s 414us/sample - loss: 0.0551 - accuracy: 0.9814\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 20s 407us/sample - loss: 0.0521 - accuracy: 0.9827\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 21s 416us/sample - loss: 0.0739 - accuracy: 0.9756\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 20s 409us/sample - loss: 0.0603 - accuracy: 0.9801\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 21s 416us/sample - loss: 0.0489 - accuracy: 0.9836\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 20s 404us/sample - loss: 0.0438 - accuracy: 0.9855\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 19s 385us/sample - loss: 0.0476 - accuracy: 0.9844\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 19s 383us/sample - loss: 0.0445 - accuracy: 0.9848\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.0452 - accuracy: 0.9846\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 19s 386us/sample - loss: 0.0422 - accuracy: 0.9860\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 19s 387us/sample - loss: 0.0416 - accuracy: 0.9861\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 19s 383us/sample - loss: 0.0401 - accuracy: 0.9872\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.0381 - accuracy: 0.9881\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0424 - accuracy: 0.9860\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0356 - accuracy: 0.9878\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 20s 390us/sample - loss: 0.0362 - accuracy: 0.9884\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 19s 390us/sample - loss: 0.0332 - accuracy: 0.9888\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0367 - accuracy: 0.9877\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0335 - accuracy: 0.9888\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 21s 416us/sample - loss: 0.0328 - accuracy: 0.9895\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 20s 405us/sample - loss: 0.0340 - accuracy: 0.9884\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 19s 385us/sample - loss: 0.0343 - accuracy: 0.9879\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0239 - accuracy: 0.9921\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 20s 391us/sample - loss: 0.0258 - accuracy: 0.9913\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 20s 401us/sample - loss: 0.0296 - accuracy: 0.9906\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 21s 417us/sample - loss: 0.0278 - accuracy: 0.9907\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 20s 404us/sample - loss: 0.0276 - accuracy: 0.9909\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 20s 401us/sample - loss: 0.0296 - accuracy: 0.9904\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 20s 390us/sample - loss: 0.0243 - accuracy: 0.9917\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 19s 390us/sample - loss: 0.0187 - accuracy: 0.9935\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 20s 397us/sample - loss: 0.0266 - accuracy: 0.9916\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 19s 385us/sample - loss: 0.0329 - accuracy: 0.9897\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 20s 394us/sample - loss: 0.0293 - accuracy: 0.9906\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 20s 391us/sample - loss: 0.0209 - accuracy: 0.9929\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 20s 398us/sample - loss: 0.0187 - accuracy: 0.9940\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0228 - accuracy: 0.9925\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 20s 397us/sample - loss: 0.0236 - accuracy: 0.9924\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0295 - accuracy: 0.9900\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 20s 394us/sample - loss: 0.0183 - accuracy: 0.9945\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 20s 397us/sample - loss: 0.0225 - accuracy: 0.9924\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 20s 401us/sample - loss: 0.0165 - accuracy: 0.9946\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 20s 402us/sample - loss: 0.0181 - accuracy: 0.9941\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 20s 402us/sample - loss: 0.0262 - accuracy: 0.9923\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0301 - accuracy: 0.9906\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 20s 400us/sample - loss: 0.0154 - accuracy: 0.9951\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0207 - accuracy: 0.9932\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0139 - accuracy: 0.9953\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0209 - accuracy: 0.9937\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 20s 396us/sample - loss: 0.0257 - accuracy: 0.9922\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 20s 395us/sample - loss: 0.0211 - accuracy: 0.9933\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 20s 397us/sample - loss: 0.0137 - accuracy: 0.9955\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 20s 396us/sample - loss: 0.0175 - accuracy: 0.9945\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 20s 394us/sample - loss: 0.0227 - accuracy: 0.9931\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 19s 390us/sample - loss: 0.0197 - accuracy: 0.9942\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 20s 396us/sample - loss: 0.0155 - accuracy: 0.9952\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 20s 396us/sample - loss: 0.0186 - accuracy: 0.9939\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 20s 394us/sample - loss: 0.0145 - accuracy: 0.9953\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 20s 394us/sample - loss: 0.0165 - accuracy: 0.9947\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0197 - accuracy: 0.9938\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 20s 394us/sample - loss: 0.0170 - accuracy: 0.9946\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 20s 394us/sample - loss: 0.0161 - accuracy: 0.9945\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0173 - accuracy: 0.9947\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 20s 392us/sample - loss: 0.0165 - accuracy: 0.9950\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 20s 392us/sample - loss: 0.0155 - accuracy: 0.9951\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 20s 390us/sample - loss: 0.0139 - accuracy: 0.9958\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 19s 388us/sample - loss: 0.0138 - accuracy: 0.9961\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0154 - accuracy: 0.9949\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 20s 390us/sample - loss: 0.0090 - accuracy: 0.9971\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 19s 387us/sample - loss: 0.0165 - accuracy: 0.9949\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 19s 387us/sample - loss: 0.0243 - accuracy: 0.9929\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 19s 386us/sample - loss: 0.0121 - accuracy: 0.9961\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 19s 388us/sample - loss: 0.0096 - accuracy: 0.9968\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 19s 387us/sample - loss: 0.0117 - accuracy: 0.9963\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 19s 385us/sample - loss: 0.0117 - accuracy: 0.9959\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 19s 386us/sample - loss: 0.0183 - accuracy: 0.9944\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 19s 387us/sample - loss: 0.0130 - accuracy: 0.9959\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 19s 386us/sample - loss: 0.0182 - accuracy: 0.9949\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 19s 386us/sample - loss: 0.0134 - accuracy: 0.9960\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 19s 386us/sample - loss: 0.0135 - accuracy: 0.9960\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 19s 387us/sample - loss: 0.0140 - accuracy: 0.9960\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 19s 385us/sample - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 19s 384us/sample - loss: 0.0119 - accuracy: 0.9964\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 19s 385us/sample - loss: 0.0139 - accuracy: 0.9956\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 19s 385us/sample - loss: 0.0192 - accuracy: 0.9944\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 19s 386us/sample - loss: 0.0128 - accuracy: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efb601bf048>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, 3,input_shape=(32,32,3),activation='relu'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, 3,input_shape=(32,32,3),activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(100,activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1181818e-09, 2.2787891e-10, 2.7641558e-05, 9.9997222e-01,\n",
       "        2.2662376e-09, 1.3709294e-09, 1.0619616e-09, 1.2446033e-09,\n",
       "        7.1685839e-08, 1.1682140e-12]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
